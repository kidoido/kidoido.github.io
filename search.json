[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Igor Domaradzki",
    "section": "",
    "text": "Cześć! Witam na mojej stronie, na której znajdziecie moje portforlio Data Science.\nJestem studentem SGH na kierunku magisterskim Analiza danych - big data.\nWcześniej ukończyłem tam licencjat na kierunku Metody ilościowe w ekonomii i systemy informacyjne, gdzie napisałem pracę licencjacką “Zastosowanie teorii gier do analizy wybranych zagadnień w sporcie”\nMoje CV\nPoniżej kilka projektów, które stworzyłem.\n\n\n\nTo ja!\n\n\nStrona stworzona z użyciem RPosit Quarto i opublikowana przez Github Pages.\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Wrapped\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime Series forecasting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel LLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlgorytm genetyczny\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFunction Factory\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCałki podwójne\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR6Class\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\nNo matching items\n\n:::\n:::"
  },
  {
    "objectID": "Projekty/Integrate3d/index.html",
    "href": "Projekty/Integrate3d/index.html",
    "title": "6. Całki podwójne",
    "section": "",
    "text": "Projekt wykonany w ramach zajęć Podstawy programowania w języku R."
  },
  {
    "objectID": "Projekty/Integrate3d/index.html#opis-projektu",
    "href": "Projekty/Integrate3d/index.html#opis-projektu",
    "title": "6. Całki podwójne",
    "section": "Opis projektu",
    "text": "Opis projektu\nZadanie w tym projekcie jest raczej proste i dotyczy obliczania całek z funkcji f:R^2 -&gt; R na przedziałach.\nW tym celu chcemy zdefiniować funkcję, która przyjmuje dwa główne argumenty: pierwszy reprezentujący matematyczną funkcję, która będzie całkowana oraz drugi, który reprezentuje przedział całkowania. Funkcja może przyjmować dodatkowe argumenty w zależności od wykorzystanego algorytmu (przykład podany poniżej). Funkcja powinna zwracać wartość obliczonej całki.\nZ technicznego punktu widzenia, chcemy zdefiowanować funkcję integrate3d(), która przyjmuje dwa argumenty:\n\nf funkcja, która jest całkowana, np., f(x,y) {x ^ 2 + y ^ 2};\nover lista zawierająca dwie pozycje, reprezentująca przedział całkowania, np., list(x = c(0,1), y = c(0, 1))."
  },
  {
    "objectID": "Projekty/Integrate3d/index.html#moje-rozwiązanie",
    "href": "Projekty/Integrate3d/index.html#moje-rozwiązanie",
    "title": "6. Całki podwójne",
    "section": "Moje rozwiązanie",
    "text": "Moje rozwiązanie\nCałkę obliczam metodą prostokątów. Z racji, że w zadaniu liczymy całki podówjne można ją nazwać metodą równoległoboków.\n\nintegrate3d &lt;- function(f, over, n = 120) {\n  # Dzielimy przestrzeń, na której całkujemy na n^2 części\n  axis_x &lt;- seq(over$x[1], over$x[2], length.out = n)\n  axis_y &lt;- seq(over$y[1], over$y[2], length.out = n)\n  \n  #Liczymy wartość całki w poszczególnych punktach i dodajemy objętości kolejnych prostopadłościanów do siebie\n  integral_sum &lt;- 0\n  for (xx in 1:(n-1)){\n    smaller_x &lt;- axis_x[xx]\n    bigger_x &lt;- axis_x[xx+1]\n    avg_x &lt;- mean(smaller_x,bigger_x)\n    for (yy in 1:(n-1)) {\n      smaller_y &lt;- axis_y[yy]\n      bigger_y &lt;- axis_y[yy+1]\n      avg_y &lt;- mean(smaller_y,bigger_y)\n      z &lt;- f(avg_x, avg_y)\n      parrallelogram_volume &lt;- (bigger_y - smaller_y)*(bigger_x - smaller_x)*z\n      integral_sum &lt;- integral_sum + parrallelogram_volume\n    }\n  }\n  return(integral_sum)\n} \n\n\n### Example 1\nintegrate3d(\n  f = function(x, y) {cos(x) * y},\n  over = list(x = c(0, pi / 2), y = c(0, 1)))\n\n[1] 0.4990634\n\n\n\n### Example 2\nintegrate3d(\n  f = function(x, y) { (cos(x) + 2) * (sin(y) + 1)},\n  over = list(x = c(0, pi), y = c(0, pi)),\n  n = 10^2)\n\n[1] 32.46768\n\n\n\n### Example 3\nintegrate3d(\n  f = function(x, y) {30 + 23*x + (13/4)*y + (28.12)*x*y - 144 * sqrt(x^2 + y^2)},\n  over = list(x = c(0, (5 * pi) / 2), y = c(0, 5)))\n\n[1] -12351.79"
  },
  {
    "objectID": "Projekty/LLM/index.html",
    "href": "Projekty/LLM/index.html",
    "title": "3. Model LLM",
    "section": "",
    "text": "Projekt wykonany w Pythonie w ramach zajęć Big Data"
  },
  {
    "objectID": "Projekty/GA/index.html",
    "href": "Projekty/GA/index.html",
    "title": "4. Algorytm genetyczny",
    "section": "",
    "text": "Projekt wykonany w Pythonie na zajęcia Credit Scoring.\nPodstawowym zagadnieniem było zbudowanie modelu do oceny ryzyka potencjalnych klientów kredytowych za pomocą kodów udostępnionych przez wykładowcę, pana dr Karola Przanowskiego. Dla chętnych była możliowość ich udoskonalenia wg własnej inwencji twórczej. Ja zdecydowałem się zaimplementować algorytm genetyczny do wyboru zmiennych modelu.\nDo wyboru w danych mieliśmy ok. 200 zmiennych, podczas gdy do modelu szukaliśmy najlepszej kombinacji kilku/kilkunastu. Funkcją celu było znalezienie modelu z jak największym indeksem Gini, mierzącym jego siłę predykcyjną.\nPoniżej zamieszczam kod, którego jestem autorem. Cały projekt, włącznie z kodem profesora, można znaleźc tutaj."
  },
  {
    "objectID": "Projekty/RWrapped/index.html",
    "href": "Projekty/RWrapped/index.html",
    "title": "1. R Wrapped",
    "section": "",
    "text": "Projekt wykonany w języku R w ramach zajęć Prezentacja i wizualizacja danych."
  },
  {
    "objectID": "Projekty/RWrapped/index.html#wprowadzenie",
    "href": "Projekty/RWrapped/index.html#wprowadzenie",
    "title": "1. R Wrapped",
    "section": "Wprowadzenie",
    "text": "Wprowadzenie\nLubię słuchać muzyki. Łącząc to z moim nauturalnym drygiem do analizy danych, od pewnego czasu dokładnie analizuję jaką muzykę słucham.\nNie jestem jedynym, który miał taki pomysł. Dla osób, które dokładnie chcą wiedzieć czego słuchają powstała strona &lt;last.fm&gt;. Tam, po połączeniu z kontem Spotify, można dokładnie zobaczyć co i o której zostało przesłuchane.\nPowstała nawet biblioteka w R autorstwa Piotra Patrzyka, która pozwala załadować dane ze swojego konta na lastFM w postaci data.frame w R\nDzięki tej bibliotece mogłem rozpocząć analizę.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(remotes)\nremotes::install_github(\"ppatrzyk/lastfmR\")\nlibrary(lastfmR)\n\nPodstawową funkcją tej biblioteki jest get_scrobbles.\n\nuser &lt;- \"c00lll\"\nscrobbles &lt;- get_scrobbles(user = user, timezone = 'Europe/Warsaw')\n\n\nhead(scrobbles,10)\n\n                   date                  artist                         track\n               &lt;POSIXt&gt;                  &lt;char&gt;                        &lt;char&gt;\n 1: 2025-02-17 00:19:32              black midi                         Still\n 2: 2025-02-16 22:37:09              black midi                         Still\n 3: 2025-02-16 22:32:27              black midi               Welcome to Hell\n 4: 2025-02-16 22:29:19              black midi                   Eat Men Eat\n 5: 2025-02-16 22:28:28 Black Country, New Road            Chaos Space Marine\n 6: 2025-02-16 21:25:22              black midi                  27 Questions\n 7: 2025-02-16 21:16:28 Black Country, New Road                    Sunglasses\n 8: 2025-02-16 21:13:29              black midi                   The Defence\n 9: 2025-02-16 20:27:01              ROLE MODEL Sally, When The Wine Runs Out\n10: 2025-02-16 20:24:03              black midi                   The Defence\n                                   album\n                                  &lt;char&gt;\n 1:                             Hellfire\n 2:                             Hellfire\n 3:                             Hellfire\n 4:                             Hellfire\n 5:                   Ants From Up There\n 6:                             Hellfire\n 7:                           Sunglasses\n 8:                             Hellfire\n 9: Kansas Anymore (The Longest Goodbye)\n10:                             Hellfire\n\n\nSortuje dane tak, aby najstarszy odsłuch był na górze. Potem zliczam, po raz który dany album/piosenka/artysta został odsłuchany. To przyda mi się później.\n\nscrobbles &lt;- scrobbles[(order(as.Date(scrobbles$date, format=\"%Y-%m-%d %H:%M:%S\"))),]\nscrobbles &lt;- scrobbles[rev(order(as.Date(scrobbles$date, format=\"%Y-%m-%d %H:%M:%S\"))),]\nscrobbles &lt;- scrobbles[(order(as.Date(scrobbles$date, format=\"%Y-%m-%d %H:%M:%S\"))),]\nscrobbles$jedynki &lt;- 1\nscrobbles$cum_sum &lt;- ave(scrobbles$jedynki, scrobbles$track, FUN=cumsum)\nscrobbles$cum_sum_artists &lt;- ave(scrobbles$jedynki, scrobbles$artist, FUN=cumsum)\nscrobbles$cum_sum_albums &lt;- ave(scrobbles$jedynki, scrobbles$album, FUN=cumsum)\nhead(scrobbles,10)\n\n                   date       artist  track         album jedynki cum_sum\n               &lt;POSIXt&gt;       &lt;char&gt; &lt;char&gt;        &lt;char&gt;   &lt;num&gt;   &lt;num&gt;\n 1: 2018-06-18 14:46:17 BROCKHAMPTON  JUNKY SATURATION II       1       1\n 2: 2018-06-18 14:51:57 BROCKHAMPTON   BANK    SATURATION       1       1\n 3: 2018-06-18 14:55:13 BROCKHAMPTON   TRIP    SATURATION       1       1\n 4: 2018-06-18 14:58:37 BROCKHAMPTON   STAR    SATURATION       1       1\n 5: 2018-06-18 15:01:18 BROCKHAMPTON   FAKE    SATURATION       1       1\n 6: 2018-06-18 22:47:18 BROCKHAMPTON   BANK    SATURATION       1       2\n 7: 2018-06-18 22:50:51 BROCKHAMPTON   TRIP    SATURATION       1       2\n 8: 2018-06-18 22:54:30 BROCKHAMPTON   STAR    SATURATION       1       2\n 9: 2018-06-18 22:56:05 BROCKHAMPTON   DIRT          Dirt       1       1\n10: 2018-06-19 00:00:01 BROCKHAMPTON   DIRT          Dirt       1       2\n    cum_sum_artists cum_sum_albums\n              &lt;num&gt;          &lt;num&gt;\n 1:               1              1\n 2:               2              1\n 3:               3              2\n 4:               4              3\n 5:               5              4\n 6:               6              5\n 7:               7              6\n 8:               8              7\n 9:               9              1\n10:              10              2"
  },
  {
    "objectID": "Projekty/RWrapped/index.html#listy-top-10",
    "href": "Projekty/RWrapped/index.html#listy-top-10",
    "title": "1. R Wrapped",
    "section": "Listy Top 10",
    "text": "Listy Top 10\nUdało się! Teraz mogę wykonać analizy. Na początek zobaczmy, jakie jest 10 piosenek z największą liczbą odtworzeń.\n\n#sortoowanie tabeli pod względem piosenek\ncount_whole &lt;- table(scrobbles$track)\ncount_whole_sorted &lt;- sort(count_whole, decreasing = T)\n#Top 10 piosenek\ntop10_tracks_sorted &lt;- head(count_whole_sorted, 10)\n\n#wydruk w konsoli top 10 piosenek\nfor (i in 1:10) {\n  cat(paste0(i, \". \", scrobbles[track == names(top10_tracks_sorted[i])]$artist[2], \" - \", names(top10_tracks_sorted[i]),\": \", as.numeric(top10_tracks_sorted[i]), \"\\n\"))\n}\n\n1. 100 gecs - money machine: 249\n2. Meek, Oh Why? - Pieśniarka i Król: 246\n3. JPEGMAFIA - 1539 N. Calvert: 206\n4. King Krule - Czech One: 190\n5. 100 gecs - hand crushed by a mallet: 189\n6. Coals - Blue (feat. Schafter): 166\n7. 100 gecs - ringtone: 158\n8. 100 gecs - sympathy 4 the grinch: 150\n9. laura les - Haunted: 149\n10. TV Girl - Blue Hair: 146\n\nfor (i in 1:10) {\n  names(top10_tracks_sorted)[i] &lt;- paste0(scrobbles[track == names(top10_tracks_sorted[i])]$artist[2], \" - \", names(top10_tracks_sorted[i]))\n}\n\nZaprezentujmy to w formie jakiegoś wykresu.\n\npar(mar=c(5,2,2,2))\npal &lt;- colorRamp(c(\"#050861\", \"#131ad6\"))\nvalues_barplot &lt;- as.numeric(rev(top10_tracks_sorted))\nkolor_barplot &lt;- rgb(pal((values_barplot - min(values_barplot))/ diff(range(values_barplot))), max=255)\nbarplot_tracks &lt;- barplot(rev(top10_tracks_sorted), horiz = T, las = 1, yaxt = \"n\", xlim=c(0, max(scrobbles$cum_sum)), col = kolor_barplot, xlab = \"Ilość odtworzeń\", main = \"Top 10 utworów wszechczasów\")\ntext(as.numeric(rev(top10_tracks_sorted)), barplot_tracks, labels = as.numeric(rev(top10_tracks_sorted)), pos = 2, col = \"white\", cex = 3/4, font = 2)\ntext(1, barplot_tracks, labels = paste0(rev(names(top10_tracks_sorted))), pos = 4, col = \"white\", cex = 0.75, font = 2)\n\n\n\n\n\n\n\n\nTo samo powtarzam z artystami, a potem z albumami\n\ncount_artist &lt;- table(scrobbles$artist)\nartist_sorted &lt;- sort(count_artist, decreasing = T)\n#Top 10 artystów\ntop10_artist_sorted &lt;- head(artist_sorted,10)\nfor (i in 1:10) {\n  cat(i, \". \", names(top10_artist_sorted[i]),\": \", as.numeric(top10_artist_sorted[i]), \"\\n\", sep = \"\")\n}\n\n1. Taco Hemingway: 3024\n2. 100 gecs: 2510\n3. JPEGMAFIA: 2133\n4. Holak: 2117\n5. Meek, Oh Why?: 1950\n6. Charli XCX: 1891\n7. BROCKHAMPTON: 1705\n8. TV Girl: 1469\n9. Kendrick Lamar: 1388\n10. ROSALÍA: 1062\n\n\n\n#plot Top 10 artystow \npar(mar=c(5,2,2,2))\ntop10_artist_sorted &lt;- head(artist_sorted,10)\npal &lt;- colorRamp(c(\"#4f1403\", \"#992c0e\"))\nvalues_barplot &lt;- as.numeric(rev(top10_artist_sorted))\nkolor_barplot &lt;- rgb(pal((values_barplot - min(values_barplot))/ diff(range(values_barplot))), max=255)\nbarplot_tracks &lt;- barplot(rev(top10_artist_sorted), horiz = T, las = 1, yaxt = \"n\", col = kolor_barplot, xlab = \"Ilość odtworzeń\", main = \"Top 10 artystów wszechczasów\")\ntext(as.numeric(rev(top10_artist_sorted)), barplot_tracks, labels = as.numeric(rev(top10_artist_sorted)), pos = 2, col = \"white\", cex = 0.8, font = 2)\ntext(1, barplot_tracks, labels = paste0(rev(names(top10_artist_sorted))), pos = 4, col = \"white\", cex = ((-0.2/3483)*(as.numeric(top10_artist_sorted[1] - top10_artist_sorted[10]) ) + 0.8), font = 2)\n\n\n\n\n\n\n\n\n\ncount_album &lt;- table(scrobbles$album)\nalbums_sorted &lt;- sort(count_album, decreasing = T)\n#Top 10 albumów\ntop10_albums_sorted &lt;- head(albums_sorted,10)\nfor (i in 1:10) {\n  cat(i, \". \", scrobbles[album == names(top10_albums_sorted[i])]$artist[2], \" - \", names(top10_albums_sorted[i]),\": \", as.numeric(top10_albums_sorted[i]), \"\\n\",sep = \"\")\n}\n\n1. Meek, Oh Why? - Zachód: 1130\n2. 100 gecs - 1000 gecs: 880\n3. Travis Scott - ASTROWORLD: 652\n4. 100 gecs - 1000 gecs and The Tree of Clues: 638\n5. BROCKHAMPTON - GINGER: 614\n6. Taco Hemingway - Marmur: 585\n7. Taco Hemingway - Café Belga: 571\n8. King Krule - The OOZ: 571\n9. Phoebe Bridgers - Punisher: 558\n10. Taco Hemingway - Pocztówka z WWA, lato '19: 556\n\nfor (i in 1:10) {\n  names(top10_albums_sorted)[i] &lt;- paste0(scrobbles[album == names(top10_albums_sorted[i])]$artist[2], \" - \", names(top10_albums_sorted[i]))\n}\n\n\npar(mar=c(5,2,2,2))\npal &lt;- colorRamp(c(\"#004f1c\", \"#0fa343\"))\nvalues_barplot &lt;- as.numeric(rev(top10_albums_sorted))\nkolor_barplot &lt;- rgb(pal((values_barplot - min(values_barplot))/ diff(range(values_barplot))), max=255)\nbarplot_tracks &lt;- barplot(rev(top10_albums_sorted), horiz = T, las = 1, yaxt = \"n\", col = kolor_barplot, xlab = \"Ilość odtworzeń\", main = \"Top 10 albumów wszechczasów\")\ntext(as.numeric(rev(top10_albums_sorted)), barplot_tracks, labels = as.numeric(rev(top10_albums_sorted)), pos = 2, col = \"white\", cex = 0.8, font = 2)\ntext(1, barplot_tracks, labels = paste0(rev(names(top10_albums_sorted))), pos = 4, col = \"white\", cex = 0.7, font = 2)"
  },
  {
    "objectID": "Projekty/RWrapped/index.html#wyścigi-utworów",
    "href": "Projekty/RWrapped/index.html#wyścigi-utworów",
    "title": "1. R Wrapped",
    "section": "Wyścigi utworów",
    "text": "Wyścigi utworów\nPowyżesze wykresy przedstawiają stan aktualny (na wrzesień 2024). Natomiast moje preferencje z czasem się zmieniały. Rozpoczynając ten projekt, właśnie to chciałem zwizualizować.\nZobaczmy, jak zmieniali się liderzy w klasyfikacji odsłuchań.\n\n#############\n#Wyścig utworów\ntop_track &lt;- scrobbles[track == names(count_whole_sorted[1]),]\n\nplot(top_track$date, top_track$cum_sum, type = \"s\", col = \"gold\", lwd=3, xlim = c(min(scrobbles$date), max(scrobbles$date)), xlab = \"Czas odsłuchu\", ylab = \"Ilość odtworzeń\", main = \"Wykres sumy odtworzeń utworów\")\n\nfor (track_name in names(count_whole_sorted[1:1000])) {\n  to_draw &lt;- scrobbles[track == track_name,]\n  lines(to_draw$date, to_draw$cum_sum, type = \"s\", col = \"#dbd7ca\")\n}\n\nlines(top_track$date, top_track$cum_sum, type = \"s\", col = \"gold\", lwd=3)\n\nmy_range &lt;- 4:10\nfor (i in my_range) {\n  to_draw &lt;- scrobbles[track == names(count_whole_sorted[i]),]\n  lines(to_draw$date, to_draw$cum_sum, type = \"s\", col = \"black\")\n}\n\ntop_track3 &lt;- scrobbles[track == names(count_whole_sorted[3]),]\nlines(top_track3$date, top_track3$cum_sum, type = \"s\", col = \"brown\", lwd = 3)\n\ntop_track2 &lt;- scrobbles[track == names(count_whole_sorted[2]),]\nlines(top_track2$date, top_track2$cum_sum, type = \"s\", col = \"grey\", lwd = 3)\n\nlines(top_track$date, top_track$cum_sum, type = \"s\", col = \"gold\", lwd=3)\n\n\nlegend(min(scrobbles$date), max(scrobbles$cum_sum), c(names(count_whole_sorted[1]), names(count_whole_sorted[2]), names(count_whole_sorted[3])), col=c(\"gold\", \"grey\", \"brown\"),lty = 1, cex=0.6, title=\"Nazwy utworów\", text.font=1) \n\n\n\n\n\n\n\n\nNajbardziej zaciekawił mnie trend, w którym wszystkie piosenki mają wielki wyskok na początku, po którym następuje zwolnienie. Jest to jak najbardziej spodziewane, ponieważ po pewnym czasie piosenki tracą na “świeżości” i przechodzę do kolejnej.\n\n#############\n#Wyścig artystow\ntop_artist &lt;- scrobbles[artist == names(artist_sorted[1]),]\n\nplot(top_artist$date, top_artist$cum_sum_artists, type = \"s\", col = \"gold\", lwd=3, xlim = c(min(scrobbles$date), max(scrobbles$date)), xlab = \"Czas odsłuchu\", ylab = \"Ilość odtworzeń\", main = \"Wykres sumy odtworzeń artystow\")\n\n\nfor (artist_name in names(artist_sorted[1:1000])) {\n  to_draw &lt;- scrobbles[artist == artist_name,]\n  lines(to_draw$date, to_draw$cum_sum_artists, type = \"s\", col = \"#dbd7ca\")\n}\n\nmy_range &lt;- 4:10\nfor (i in my_range) {\n  to_draw &lt;- scrobbles[artist == names(artist_sorted[i]),]\n  lines(to_draw$date, to_draw$cum_sum_artists, type = \"s\", col = \"black\")\n}\n\ntop_artist3 &lt;- scrobbles[artist  == names(artist_sorted[3]),]\nlines(top_artist3$date, top_artist3$cum_sum_artists, type = \"s\", col = \"brown\", lwd = 3)\n\ntop_artist2 &lt;- scrobbles[artist  == names(artist_sorted[2]),]\n\nlines(top_artist2$date, top_artist2$cum_sum_artists, type = \"s\", col = \"grey\", lwd = 3)\nlines(top_artist$date, top_artist$cum_sum_artists, type = \"s\", col = \"gold\", lwd=3)\n\n\n\nlegend(min(scrobbles$date), max(scrobbles$cum_sum_artists), c(names(artist_sorted[1]), names(artist_sorted[2]), names(artist_sorted[3])), col=c(\"gold\", \"grey\", \"brown\"),lty = 1, cex=0.6, title=\"Nazwy artystów\", text.font=1) \n\n\n\n\n\n\n\n\n\n#####\n#Wyścig  albumów\ntop_album &lt;- scrobbles[album == names(albums_sorted[1]),]\n\nplot(top_album$date, top_album$cum_sum_albums, type = \"s\", col = \"gold\", lwd=3, xlim = c(min(scrobbles$date), max(scrobbles$date)), xlab = \"Moment odsłuchu\", ylab = \"Ilość odtworzeń\", main = \"Wykres sumy odtworzeń albumów\")\n\nfor (album_name in names(albums_sorted[1:1000])) {\n  to_draw &lt;- scrobbles[album == album_name,]\n  lines(to_draw$date, to_draw$cum_sum_albums, type = \"s\", col = \"#dbd7ca\")\n}\n\n\nmy_range &lt;- 4:10\nfor (i in my_range) {\n  to_draw &lt;- scrobbles[album == names(albums_sorted[i]),]\n  lines(to_draw$date, to_draw$cum_sum_albums, type = \"s\", col = \"black\")\n}\n\n\ntop_album3 &lt;- scrobbles[album  == names(albums_sorted[3]),]\nlines(top_album3$date, top_album3$cum_sum_albums, type = \"s\", col = \"brown\", lwd = 3)\n\ntop_album2 &lt;- scrobbles[album  == names(albums_sorted[2]),]\nlines(top_album2$date, top_album2$cum_sum_albums, type = \"s\", col = \"grey\", lwd = 3)\n\nlines(top_album$date, top_album$cum_sum_albums, type = \"s\", col = \"gold\", lwd=3)\n\n\nlegend(min(scrobbles$date), max(scrobbles$cum_sum_albums), c(names(albums_sorted[1]), names(albums_sorted[2]), names(albums_sorted[3])), col=c(\"gold\", \"grey\", \"brown\"),lty = 1, cex=0.7, title=\"Nazwy albumów\", text.font=1)"
  },
  {
    "objectID": "Projekty/RWrapped/index.html#ggplot2",
    "href": "Projekty/RWrapped/index.html#ggplot2",
    "title": "1. R Wrapped",
    "section": "ggplot2",
    "text": "ggplot2\nInną rzeczą, którą chciałem sprawdzić jest to jak zmieniały się moje nawyki melomana podczas okresu zbierania danych. Czy teraz słucham więcej muzyki niż kiedyś?\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nscrobbles_copy &lt;- scrobbles\n\ntibble_months &lt;- (scrobbles_copy  %&gt;% \n         group_by(month = lubridate::floor_date(date, 'month')) %&gt;%\n         summarize(l_wystapien = sum(jedynki)))\n\ntibble_months$month_name &lt;- month(tibble_months$month)\ntibble_months$year  &lt;- year(tibble_months$month)\n\nfirst_year &lt;- tibble_months$year |&gt; head(1)\ncurrent_year &lt;- tibble_months$year |&gt; tail(1)\n# Heatmap \nggplot(tibble_months, aes(year, month_name)) + \n  geom_tile(aes(fill= l_wystapien), col = \"white\") +\n  scale_fill_gradient(low = \"#fac8d8\", high = \"#87002b\", name = \"Odtworzenia\") +\n  ggtitle(\"Liczba odsłuchań danego miesiąca\") +\n  scale_y_reverse() + scale_x_discrete(limits=first_year:current_year)+\n  xlab(\"Rok\") + ylab(\"Miesiąc\")\n\n\n\n\n\n\n\n#heatmap z wartosciami\nggplot(tibble_months, aes(year, month_name)) + \n  geom_tile(aes(fill= l_wystapien), col = \"white\") +\n  scale_fill_gradient(low = \"#fac8d8\", high = \"#87002b\", name = \"Odtworzenia\") +\n  ggtitle(\"Liczba odsłuchań danego miesiąca\") +\n  scale_x_discrete(limits=first_year:current_year)+\n  xlab(\"Rok\") + ylab(\"Miesiąc\") + \n  geom_text(aes(label = l_wystapien), col = \"white\", cex = 4.5) +\n  scale_y_reverse()\n\n\n\n\n\n\n\n\nJednak więcej słuchałem kiedyś… Co ciekawe po rozpoczęciu pandemii w marcu 2020 roku liczba odtworzeń się drastycznie zmniejszyła. Można się było spodziewać, że miałem więcej wolengo czasu na słuchanie muzyki, lecz to jednak słuchanie muzyki w drodze do szkoły czy pracy nakręcało największe liczby.\nInnym pytaniem jest co wydarzyło się w czerwcu 2024 roku? Był to dla mnie intensywny okres sesji, podczas którego wspomagałem się muzyką. Natomiast rozmiar tego wsparcia mocno mnie zaskoczył!\nJacy sąc najczęsciej słuchani artyści w każdym miesiącu?\n\n### najpopularniejsci artysci dla kazdego miesiaca\nlibrary(zoo)\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:data.table':\n\n    yearmon, yearqtr\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\nfirst_scrobble_date &lt;- scrobbles$date[1]\nn_months &lt;- 1 + interval(as.yearmon(first_scrobble_date), today()) %/% months(1)\ndetach(\"package:zoo\", unload = TRUE)\n#rządy to miesiące, kolumny to lata\n# Pierwsszy rok, nie musial sie zaczac w styczniu\nfirst_scrobble_date_month &lt;- month(first_scrobble_date)\n\nif ((n_months - (12 - first_scrobble_date_month + 1)) %% 12 != 0) {\nliczbLat &lt;- ceiling((n_months - (12 - first_scrobble_date_month + 1))/12) + 1\n} else {\nliczbLat &lt;- ceiling((n_months - (12 - first_scrobble_date_month + 1))/12)  \n}\n\n\nmacierz &lt;- matrix(NA, nrow = 12, ncol = liczbLat)\nmacierz_to_plot &lt;- matrix(NA, n_months, 2)\ndate_temp &lt;- min(scrobbles_copy$date)\ndate_temp &lt;- floor_date(date_temp, 'month')\ndate_temp_next &lt;- date_temp %m+% months(1)\npier_mies = first_scrobble_date_month\nfor (i in 1:n_months) {\n  month_in_scr &lt;- scrobbles[scrobbles$date &gt; date_temp & scrobbles$date &lt; date_temp_next]\n  t_month_in_scr &lt;- table(month_in_scr$artist)\n  t_month_in_scr &lt;- sort(t_month_in_scr, decreasing = T)\n  naj_artysta &lt;- names(t_month_in_scr[1])\n  if (is.null(naj_artysta)) {\n    naj_artysta = \"No data for this month\"\n    ich_odtworzenia_wtedy = 0\n    } else {\n  ich_odtworzenia_wtedy &lt;- as.numeric(t_month_in_scr[1])\n    }\n  date_temp_next &lt;- date_temp_next %m+% months(1)\n  date_temp &lt;- date_temp %m+% months(1)\n  macierz[pier_mies] = naj_artysta\n  macierz_to_plot[pier_mies-first_scrobble_date_month+1, 1] = substr(naj_artysta,1,26)\n  macierz_to_plot[pier_mies-first_scrobble_date_month+1, 2] = ich_odtworzenia_wtedy\n  pier_mies &lt;- pier_mies + 1\n}\n#macierz\n#macierz_to_plot\n\nmacierz &lt;- matrix(macierz, nrow = 12, ncol = ceiling(length(macierz)/12))\nif (year(scrobbles$date) %&gt;% unique() %&gt;% length() != 1){\n  colnames(macierz) &lt;- year(first_scrobble_date):year(tail(scrobbles$date,1))\n  rownames(macierz) &lt;- c(\"Styczeń\", \"Luty\", \"Marzec\", \"Kwiecień\", \"Maj\", \"Czerwiec\", \"Lipiec\", \"Sierpień\", \"Wrzesień\", \"Październik\", \"Listopad\", \"Grudzień\")\n}\n\n\ndf_barplot &lt;- as.data.frame(macierz_to_plot)\n\n## To add, if len(df_barplot) != len(tibble_months), go by row in tibble months and ad missing months\ndf_barplot$month_name &lt;- c(tibble_months$month_name)\ndf_barplot$year &lt;- c(tibble_months$year)\n\nnames(df_barplot)[1:2] &lt;- c(\"Artysta\", \"Wystapienia_w_mies\")\n\ntibble_barplot &lt;- as_tibble(df_barplot)\ntibble_barplot$Wystapienia_w_mies &lt;- as.double(tibble_barplot$Wystapienia_w_mies)\n\ng &lt;- ggplot(tibble_barplot, aes(year, as.numeric(month_name))) + \n  geom_tile(aes(fill= as.double(Wystapienia_w_mies)), col = \"white\") +\n  scale_fill_gradient(low = \"#e5ced4\", high = \"#451350\", name = \"Odtworzenia \\n w miesiącu\") +\n  ggtitle(\"Liczba odsłuchań najczęściej słuchanego artysty danego miesiąca\") +\n  scale_x_discrete(limits=year(first_scrobble_date):year(tail(scrobbles$date,1)))+\n  xlab(\"Rok\") + ylab(\"Miesiąc\") +\n  scale_y_reverse() +\n  geom_text(aes(label = substr(Artysta, 1, 14)), col = \"white\", font = 2, size = 2.5)\ng\n\n\n\n\n\n\n\n\nDzięki temu wykresowi możemy zobaczyć, że do wysokiego wyniku w czerwcu 2024 przyczyniła się premiera nowego albumu Charli XCX pt. “brat”\nSpójrzmy w jakich miesiącach roku, słuchałem najwięcej.\n\n#Średnia Liczba odtworzeń na miesiąc\nsrednie_wartosci &lt;- tibble_months %&gt;%\n  group_by(month_name) %&gt;%\n  summarise(SredniaWartosc = mean(l_wystapien))\n\nsrednie_wartosci &lt;- setNames(srednie_wartosci, c(\"Miesiąc\", \"Średnia Liczba odtworzeń na miesiąc\"))\nsrednie_wartosci$Miesiąc &lt;- factor(month.name[srednie_wartosci$Miesiąc], levels = month.name)\n\n\npar(mar=c(5,6,3,3))\npal &lt;- colorRamp(c(\"#37420D\", \"#9CBD26\"))\nvalues_barplot &lt;- as.numeric(rev(srednie_wartosci$`Średnia Liczba odtworzeń na miesiąc`))\nkolor_barplot &lt;- rgb(pal((values_barplot - min(values_barplot))/ diff(range(values_barplot))), max=255)\nbarplot_mies &lt;- barplot(rev(srednie_wartosci$`Średnia Liczba odtworzeń na miesiąc`), names = rev(srednie_wartosci$Miesiąc), las = 1, xlim=c(0,max(srednie_wartosci$`Średnia Liczba odtworzeń na miesiąc`)), horiz = T, col = kolor_barplot, xlab = \"Ilość odtworzeń\", main = \"Średnia liczba odtworzeń w miesiącu\")\ntext(((max(srednie_wartosci$`Średnia Liczba odtworzeń na miesiąc`))/30), barplot_mies, labels = round(rev(srednie_wartosci$`Średnia Liczba odtworzeń na miesiąc`)), col = \"white\", font = 2, cex = 0.9)\n\n\n\n\n\n\n\n\nOraz sprójrzmy w jakich latach słuchałem najwięcej\n\nby_year &lt;- aggregate(l_wystapien ~ year, data=tibble_months, sum)\n#Todo: if a year is missing, add it and count 0\nby_year &lt;- setNames(by_year, c(\"Rok\", \"Liczba odtworzeń\"))\n\nbarplot_przed_usr &lt;- barplot(by_year[,2], names = by_year[,1], ylim = c(0,18000), main = \"Liczba odtworzeń w ciągu roku\", col = \"#aa5555\")\ntext(barplot_przed_usr, by_year[,2] + 650, labels = by_year[,2])\n\n\n\n\n\n\n\n#Srednia odtworzen na miesiąc podczas danego roku\nif ((n_months - (12 - first_scrobble_date_month + 1)) %% 12 &gt; 0) {\nby_year$l_miesiecy &lt;-c(12 - first_scrobble_date_month + 1,rep(12, length.out = floor((n_months - (12 - first_scrobble_date_month + 1))/12)),(n_months - (12 - first_scrobble_date_month + 1)) %% 12)\n} else {\n  by_year$l_miesiecy &lt;-c(12 - first_scrobble_date_month + 1,rep(12, length.out = floor((n_months - (12 - first_scrobble_date_month + 1))/12)))\n}\n\n\n\nby_year$na_mies &lt;- by_year$`Liczba odtworzeń` / by_year$l_miesiecy\nby_year$na_mies &lt;- round(by_year$na_mies,0)\n#t(by_year)\npokaz_by_year &lt;- t(by_year[c(1,4)])\n#pokaz_by_year\nbarplot_lata &lt;- barplot(pokaz_by_year[2,], names = pokaz_by_year[1,], col = \"#aa5555\", main = \"Średnia liczba odtworzeń na miesiąc\")\ntext(barplot_lata, pokaz_by_year[2,] + 50, labels = pokaz_by_year[2,])\n\n\n\n\n\n\n\n\nTeraz zobaczmy, w jakich godzinach dnia najczęściej słucham muzyki.\n\nlibrary(lubridate)\n#heat map dzien/godzina\nday_plot &lt;- (scrobbles_copy  %&gt;% \n         group_by(date = lubridate::floor_date(date, 'hour')) %&gt;%\n         summarize(l_wystapien = sum(jedynki)))\n\n#day_plot$day &lt;- wday(day_plot$date, week_start = getOption(\"lubridate.week.start\", 1))\n\nday_plot$day &lt;- wday(day_plot$date - days(1))\nday_plot$hour  &lt;- hour(day_plot$date)\n\nday_plot_to_draw &lt;- day_plot %&gt;%\n  group_by(day, hour) %&gt;%\n  summarise(Suma = sum(l_wystapien))\n\n`summarise()` has grouped output by 'day'. You can override using the `.groups`\nargument.\n\n# Heatmap \ng &lt;- ggplot(day_plot_to_draw, aes(day, hour)) + \n  geom_tile(aes(fill= Suma), col = \"white\") +\n  scale_fill_gradient(low = \"#fad8e8\", high = \"#67000b\", name = \"Odtworzenia\") +\n  ggtitle(\"Liczba odsłuchań o danej pory dnia\")  + scale_x_discrete(limits=1:7, labels = c(\"Poniedziałek\", \"Wtorek\", \"Środa\", \"Czwartek\", \"Piątek\", \"Sobota\", \"Niedziela\")) +\n  scale_y_discrete(limits=0:23) + xlab(\"Dzień tygodnia\") + ylab(\"Godzina\")\ng\n\n\n\n\n\n\n\n#dodanie wartości na mapę\ng + geom_text(aes(label = Suma), col = \"white\", cex = 3)\n\n\n\n\n\n\n\n# dzien i godzina z najwieksza iloscia odsłuchań\nday_plot_to_draw[which.max(day_plot_to_draw$Suma),]\n\n# A tibble: 1 × 3\n# Groups:   day [1]\n    day  hour  Suma\n  &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1     2    17   975\n\n\nKrólują godziny popołudniowe powrotu ze szkoły i pracy. Najwięcej we wtorek o godz. 17."
  },
  {
    "objectID": "Projekty/RWrapped/index.html#chmura-gatunków",
    "href": "Projekty/RWrapped/index.html#chmura-gatunków",
    "title": "1. R Wrapped",
    "section": "Chmura gatunków",
    "text": "Chmura gatunków\nZobaczmy jakie gatunki najczęsciej się przewijają u artysów, których słucham.\n\nartist_info &lt;- get_library_info(user = user)\n\n\nlibrary(stringr)\nlibrary(wordcloud)\n\nLoading required package: RColorBrewer\n\n#wordcloud\n\nartist_info$genres &lt;- str_split(artist_info$artist_tags, \"; \")\ngenres_unlisted &lt;- unlist(artist_info$genres)\n\n# Utworzenie tabeli częstości gatunków\ntabela_czestosci_gatunkow &lt;- table(genres_unlisted)\nlista_nazw_gat &lt;- names(tabela_czestosci_gatunkow)\n\n#chmura słów\npar(mar=c(2,2,2,2))\nwordcloud(lista_nazw_gat, as.numeric(tabela_czestosci_gatunkow), colors = c(\"#101112\", \"#384a8c\", \"#db8904\"))\n\n\n\n\n\n\n\n\n\nnajczestszy_gatunek &lt;- names(tabela_czestosci_gatunkow)[which.max(tabela_czestosci_gatunkow)]\n\ntest_cgest &lt;- rev(sort(tabela_czestosci_gatunkow, deacreasing = T))\n#test_cgest[1]\n\n# Lista najczęstszych gatunków wśrod artystów\nfor (i in 1:10){\n  cat(paste0(i, \". \", names(test_cgest[i]), \": \", as.numeric(test_cgest[i]), \"\\n\"))\n}\n\n1. electronic: 345\n2. Hip-Hop: 321\n3. rap: 297\n4. seen live: 279\n5. pop: 224\n6. indie: 203\n7. hip hop: 153\n8. experimental: 114\n9. hyperpop: 111\n10. female vocalists: 110\n\ntc &lt;- head(test_cgest,10)\npar(mar=c(5,2,2,2))\npal &lt;- colorRamp(c(\"#050861\", \"#131ad6\"))\nvalues_barplot &lt;- as.numeric(rev(tc))\nkolor_barplot &lt;- rgb(pal((values_barplot - min(values_barplot))/ diff(range(values_barplot))), max=255)\nbarplot_tracks &lt;- barplot(rev(tc), horiz = T, las = 1, yaxt = \"n\", col = kolor_barplot, xlab = \"Ilość odtworzeń\", main = \"Najczęstrze tagi wśród artystów\")\ntext(as.numeric(rev(tc)), barplot_tracks, labels = as.numeric(rev(tc)), pos = 2, col = \"white\", cex = 0.8, font = 2)\ntext(1, barplot_tracks, labels = paste0(rev(names(tc))), pos = 4, col = \"white\", cex = 0.8, font = 2)"
  },
  {
    "objectID": "Projekty/TS/index.html",
    "href": "Projekty/TS/index.html",
    "title": "2. Time Series forecasting",
    "section": "",
    "text": "Projekt wykonany w języku R w ramach zajęć Applied Macroeconometrics."
  },
  {
    "objectID": "Projekty/TS/index.html#time-series-forecasting",
    "href": "Projekty/TS/index.html#time-series-forecasting",
    "title": "2. Time Series forecasting",
    "section": "Time series forecasting",
    "text": "Time series forecasting\nPodczas mojej wymiany studenckiej w Neuchâtel miałem przyjemność uczestniczyć w zajęciach z makroekonometrii stosowanej, prowadzonych przez prof. Daniela Kaufmana. Na zajęciach uczyliśmy się prognozowania makroekonomicznych szeregów czasowych, a jednym z elementów zaliczenia było przygotowanie prognozy wskaźnika wyznaczonego przez profesora. Moim zadaniem było opracowanie prognozy wartości wskaźnika podaży pieniądza M3 dla Szwajcarii.\nOto mój kod, który zastosowałem do wykonania prognozy.\n\nlibrary(readxl)\nlibrary(xts)\nlibrary(dplyr)\nlibrary(tsbox)\nlibrary(CADFtest)\nlibrary(forecast)\nlibrary(ggplot2)\nlibrary(seasonal)\nlibrary(lmtest)\n\nHistoryczne wartości wskaźnika M3 pobrałem ze strony Szwajcarskiego Banku Centralnego.\n\ndata &lt;- read_excel(\"snb-chart-data-snbmonagglech-en-all-20241021_0900.xlsx\", \n                   skip = 15) # First 15 lines of the file are the information about the data\n\n# Let's inspect the data\n\ndata %&gt;% head(5)\n\n# A tibble: 5 × 9\n  ...1    `Currency in circulation` `Sight deposits` Deposits in transaction a…¹\n  &lt;chr&gt;                       &lt;dbl&gt;            &lt;dbl&gt;                       &lt;dbl&gt;\n1 1984-12                      23.7             44.4                        27.3\n2 1985-01                      22.2             41.6                        28.0\n3 1985-02                      22.2             38.6                        28.4\n4 1985-03                      22.3             39.6                        28.3\n5 1985-04                      22.0             40.0                        28.4\n# ℹ abbreviated name: ¹​`Deposits in transaction accounts`\n# ℹ 5 more variables: `Savings deposits` &lt;dbl&gt;, `Time deposits` &lt;dbl&gt;,\n#   M1 &lt;dbl&gt;, M2 &lt;dbl&gt;, M3 &lt;dbl&gt;\n\n\n\nStacjonarność szeregu\nZobaczymy jak dane prezentują się na wykresie.\n\n# Modifying the date vector to convert it later to a POSIX format\nM3 &lt;- xts(x = data$M3,\n          order.by= as.Date(sapply(data[,1], paste0, \"-01\"))\n)\n\nts_plot(M3, \n        title = \"Swiss Monetary aggregate M3 over time\",\n        subtitle = \"in billions of CHF\",\n        ylab = \"CHF billions\")\n\n\n\n\n\n\n\n\nWizualnie można zauważyć, że poziom M3 nie jest stacjonarny i wykazuje trend rosnący.\nSprawdźmy to również matematycznie.\nDo tego użyję testu Augmented Dickey-Fuller (ADF), który służy do sprawdzania, czy szereg czasowy jest stacjonarny.\n\nunitRootTest &lt;- CADFtest(M3, type = \"trend\", max.lag.y=10)\nsummary(unitRootTest)\n\nAugmented DF test \n                                             ADF test\nt-test statistic:                          -1.4983573\np-value:                                    0.8291424\nMax lag of the diff. dependent variable:   10.0000000\n\nCall:\ndynlm(formula = formula(model), start = obs.1, end = obs.T)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-14.6944  -2.3640   0.2272   2.3451  15.3185 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.522721   0.614911   2.476 0.013638 *  \ntrnd         0.010613   0.006340   1.674 0.094817 .  \nL(y, 1)     -0.004497   0.003001  -1.498 0.829142    \nL(d(y), 1)   0.109869   0.046814   2.347 0.019357 *  \nL(d(y), 2)  -0.009863   0.046899  -0.210 0.833526    \nL(d(y), 3)   0.215642   0.046840   4.604 5.39e-06 ***\nL(d(y), 4)   0.042155   0.047272   0.892 0.373000    \nL(d(y), 5)  -0.049811   0.047393  -1.051 0.293816    \nL(d(y), 6)   0.097265   0.047411   2.052 0.040790 *  \nL(d(y), 7)  -0.174298   0.047666  -3.657 0.000285 ***\nL(d(y), 8)   0.041753   0.047302   0.883 0.377876    \nL(d(y), 9)   0.104568   0.047378   2.207 0.027807 *  \nL(d(y), 10)  0.030430   0.047362   0.642 0.520873    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.908 on 454 degrees of freedom\nMultiple R-squared:  0.126, Adjusted R-squared:  0.1029 \nF-statistic: 6.088 on 10 and 454 DF,  p-value: 1.016e-08\n\n\nHipoteza zerowa testu Dickey-Fuller mówi o tym, że szereg czasowy jest niestacjonarny. W teście p-value wynosi około 0,8 a to oznacza że nie ma podstaw do odrzucenia hipotezy zerowej.\nAby usunąć trend i przekształcić szereg w stacjonarny, muszę zróżnicować dane. Robię to obliczając procentowe zmiany szeregu czasowego za pomocą funkcji ts_pc().\n\nts_plot(ts_pc(M3), \n        title = \"Swiss Monetary aggregate M3 over time\",\n        subtitle = \"month to month percentage change\",\n        ylab = \"%\")\n\n\n\n\n\n\n\n\nWizualnie nie widzę większego trendu, ale sprawdźmy to za pomocą testu ADF.\n\nunitRootTest &lt;- CADFtest(ts_pc(M3), type = \"drift\", max.lag.y=10)\nsummary(unitRootTest)\n\nAugmented DF test \n                                                ADF test\nt-test statistic:                          -5.1349687627\np-value:                                    0.0000140977\nMax lag of the diff. dependent variable:   10.0000000000\n\nCall:\ndynlm(formula = formula(model), start = obs.1, end = obs.T)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.31049 -0.40007  0.00915  0.33484  1.86934 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.19675    0.04853   4.054 5.92e-05 ***\nL(y, 1)     -0.61773    0.12030  -5.135 1.41e-05 ***\nL(d(y), 1)  -0.22043    0.11685  -1.886  0.05987 .  \nL(d(y), 2)  -0.25948    0.11201  -2.317  0.02097 *  \nL(d(y), 3)  -0.08458    0.10568  -0.800  0.42393    \nL(d(y), 4)  -0.10319    0.09877  -1.045  0.29669    \nL(d(y), 5)  -0.17109    0.09360  -1.828  0.06823 .  \nL(d(y), 6)  -0.05818    0.08609  -0.676  0.49950    \nL(d(y), 7)  -0.19022    0.07908  -2.405  0.01655 *  \nL(d(y), 8)  -0.20980    0.07231  -2.902  0.00389 ** \nL(d(y), 9)  -0.12590    0.06040  -2.084  0.03768 *  \nL(d(y), 10) -0.10073    0.04639  -2.172  0.03040 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6302 on 454 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.4839,    Adjusted R-squared:  0.4714 \nF-statistic: 4.536 on 10 and 454 DF,  p-value: 3.868e-06\n\n\nP-value jest bardzo małe, szereg jest stacjonarny wokół stałej średniej. To na nim mogę teraz wykonać analizę. Przy interpretacji wyników trzeba pamiętać o powrotnej transformacji szeregu do oryginalnej formy.\nTeraz sprawdźmy czy występuje sezonowość. Jeśli tak to trzeba będzie ją usunąć.\n\nacf(as.numeric(na.omit(ts_pc(M3))), lag.max = 24, plot = T)\n\n\n\n\n\n\n\n\nTak, sezonowość występuje. Widzimy to po znaczącej autokorelacji na dwunastym i dwudziestym czwartym opóźnieniu.\nAby usunąć sezonowość, zastosuję bibliotekę seasonal.\nZobaczymy jak wygląda wykres wskaźnika po usunięciu sezonowości.\n\nM3seas &lt;- final(seas(ts_ts(M3)))\n\n# The data is not stationary\nts_plot(M3seas, \n        title = \"Swiss Monetary aggregate M3 over time\",\n        subtitle = \"seasonally adjusted, in billions of CHF\",\n        ylab = \"CHF billions\")\n\n\n\n\n\n\n\n\nSprawdźmy czy na pewno szereg czasowy zróżnicowany zmianami procentowymi z miesiąca na miesiąc nadal jest stacjonarny.\n\nM3seas_pc &lt;- ts_pc(M3seas)\nts_plot(M3seas_pc, \n        title = \"Swiss Monetary aggregate M3 over time\",\n        subtitle = \"Seasonly adjusted, month to month percentage change\",\n        ylab = \"%\")\n\n\n\n\n\n\n\n\n\n# The month on month growth rate is stationary \n\nunitRootTest &lt;- CADFtest(M3seas_pc, type = \"drift\", max.lag.y=10)\nsummary(unitRootTest)\n\nAugmented DF test \n                                                ADF test\nt-test statistic:                          -4.1864117563\np-value:                                    0.0007741003\nMax lag of the diff. dependent variable:   10.0000000000\n\nCall:\ndynlm(formula = formula(model), start = obs.1, end = obs.T)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.38265 -0.26569 -0.03447  0.25565  1.45380 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.12018    0.03632   3.309 0.001012 ** \nL(y, 1)     -0.37936    0.09062  -4.186 0.000774 ***\nL(d(y), 1)  -0.52249    0.09366  -5.578 4.18e-08 ***\nL(d(y), 2)  -0.51053    0.09435  -5.411 1.02e-07 ***\nL(d(y), 3)  -0.34446    0.09478  -3.634 0.000311 ***\nL(d(y), 4)  -0.21890    0.09283  -2.358 0.018794 *  \nL(d(y), 5)  -0.16850    0.09058  -1.860 0.063479 .  \nL(d(y), 6)  -0.09920    0.08707  -1.139 0.255209    \nL(d(y), 7)  -0.16145    0.08254  -1.956 0.051075 .  \nL(d(y), 8)  -0.09718    0.07541  -1.289 0.198122    \nL(d(y), 9)  -0.09096    0.06300  -1.444 0.149500    \nL(d(y), 10)  0.01368    0.04691   0.292 0.770646    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4687 on 454 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.4696,    Adjusted R-squared:  0.4568 \nF-statistic:  4.81 on 10 and 454 DF,  p-value: 1.364e-06\n\n\nSzereg czasowy po usunięciu sezonowości nadal jest stacjonarny.\n\n\nPrognozowanie\nTeraz możemy przejść do prognozowania. Do tego użyje modelu ARMA.\nModele ARMA to modele szeregów czasowych łączące składnik autoregresyjny (AR), który opisuje zależność wartości od jej wcześniejszych obserwacji, oraz składnik średniej ruchomej (MA), uwzględniający wpływ losowych szoków z przeszłości, co pozwala na modelowanie i prognozowanie stacjonarnych szeregów czasowych.\nPytaniem jest jaka kombinacja składników autoregresyjnych oraz składników średniej ruchomej jest optymalna w modelu. W tym celu, jako że dane są na małą skalę, zbuduje pewną kombinacje możliwych modeli, i porównam ich wydajność za pomocą kryteriów informacji AIC i BIC.\n\nmaxP = 6   # Maksymalna liczba opóźnień AR\nmaxQ = 6   # Maksymalna liczba opóźnień MA\n\n# Obiekty do przechowywania kryteriów dla każdej możliwej struktury opóźnień\nAIC = matrix(data=NA, nrow=maxP+1, ncol=maxQ+1)\nBIC = matrix(data=NA, nrow=maxP+1, ncol=maxQ+1)\ncolnames(AIC) = 0:maxQ\ncolnames(BIC) = 0:maxQ\nrownames(AIC) = 0:maxP\nrownames(BIC) = 0:maxP\n\nfor (p in 0:maxP) {\n  for (q in 0:maxQ) {\n    \n    # Estymacja odpowiadającego modelu\n    temp = Arima(M3seas_pc, order = c(p, 0, q), include.constant= TRUE)\n    \n    # Zapisanie wartości kryteriów informacyjnych\n    AIC[p+1, q+1] = temp$aic\n    BIC[p+1, q+1] = temp$bic\n  }\n}\n\nSzukam modelu z najmniejszą wartością dla kryterium informacji.\n\nAIC\n\n         0        1        2        3        4        5        6\n0 678.6017 668.3649 669.0846 660.0338 647.6331 648.3763 644.2565\n1 666.6294 636.3683 638.1433 635.0882 636.8612 636.7496 644.8954\n2 665.1816 638.1987 639.9939 637.0009 637.5174 635.8337 637.7898\n3 648.6618 634.1922 636.1897 637.9341 629.8655 631.0898 632.9613\n4 639.6590 636.1950 636.8638 630.4075 631.4514 633.5779 633.0437\n5 639.1741 637.4469 638.0488 630.2042 631.7726 617.7698 619.7642\n6 637.6899 637.6001 634.4529 631.3581 624.8577 629.4724 621.7233\n\n\nDla AIC będzie to 5 5\n\nBIC\n\n         0        1        2        3        4        5        6\n0 686.9368 680.8674 685.7546 680.8713 672.6382 677.5489 677.5967\n1 679.1319 653.0384 658.9809 660.0933 666.0339 670.0898 682.4031\n2 681.8517 659.0363 664.9990 666.1735 670.8575 673.3414 679.4650\n3 669.4993 659.1973 665.3623 671.2742 667.3731 672.7649 678.8040\n4 664.6641 665.3676 670.2040 667.9152 673.1265 679.4205 683.0539\n5 668.3467 670.7870 675.5565 671.8793 677.6152 667.7800 673.9419\n6 671.0300 675.1078 676.1281 677.2008 674.8678 683.6501 680.0685\n\n\nA dla BIC jest to 1 1\nTak, więc najlepsze modele to 1 1 oraz 5 5. Porównajmy je teraz.\n\n# ARMA(1,1)\nModel &lt;- Arima(M3seas_pc, order = c(1, 0, 1), include.constant= TRUE)\nsum &lt;- summary(Model)\nsum\n\nSeries: M3seas_pc \nARIMA(1,0,1) with non-zero mean \n\nCoefficients:\n         ar1      ma1    mean\n      0.9444  -0.8404  0.3208\ns.e.  0.0270   0.0431  0.0600\n\nsigma^2 = 0.2198:  log likelihood = -314.18\nAIC=636.37   AICc=636.45   BIC=653.04\n\nTraining set error measures:\n                       ME      RMSE       MAE      MPE     MAPE      MASE\nTraining set -0.001517333 0.4673958 0.3575627 58.35058 199.3537 0.6488185\n                    ACF1\nTraining set -0.01533273\n\n\n\ncheckresiduals(Model) # The lag 12 months is significant\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,0,1) with non-zero mean\nQ* = 41.554, df = 22, p-value = 0.007075\n\nModel df: 2.   Total lags used: 24\n\n\nZauważam że Autoregresja 12 rzędu ma znaczącą autokorelację. Rozkład reszt odbiega też od postaci normalnej. Sprawdźmy czy w resztach modelu występuje autokorelacja. Robię to z pomocą testu Ljung-Box. Hipoteza zerowa stanowi, że wśród reszt nie ma autokorelacji.\n\nbox &lt;- Box.test(Model$residuals, lag=24, fitdf=1, type=\"Lj\")\nbox # P value is 0.01\n\n\n    Box-Ljung test\n\ndata:  Model$residuals\nX-squared = 41.554, df = 23, p-value = 0.01023\n\n\nP value wynosi 0,01, więc odrzucamy hipotezę zerową. Wśród reszty występuje autokorelacja.\nSprawdźmy jak wypada drugi model.\n\n# ARMA (5,5)\nModel5_5 &lt;- Arima(M3seas_pc, order = c(5, 0, 5), include.constant= TRUE)\nsum &lt;- summary(Model5_5)\nsum\n\nSeries: M3seas_pc \nARIMA(5,0,5) with non-zero mean \n\nCoefficients:\n         ar1     ar2      ar3      ar4     ar5      ma1      ma2     ma3\n      0.1861  0.3803  -0.3290  -0.2260  0.7795  -0.0859  -0.3415  0.4768\ns.e.  0.0555  0.0450   0.0424   0.0418  0.0388   0.0594   0.0430  0.0267\n         ma4      ma5   mean\n      0.3836  -0.8179  0.320\ns.e.  0.0393   0.0523  0.059\n\nsigma^2 = 0.2053:  log likelihood = -296.88\nAIC=617.77   AICc=618.44   BIC=667.78\n\nTraining set error measures:\n                       ME      RMSE       MAE      MPE     MAPE      MASE\nTraining set -0.001012154 0.4478029 0.3407682 44.87703 178.0506 0.6183438\n                    ACF1\nTraining set 0.002370316\n\n\n\ncheckresiduals(Model5_5) # There is no significance on the 12th leg\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(5,0,5) with non-zero mean\nQ* = 20.226, df = 14, p-value = 0.1232\n\nModel df: 10.   Total lags used: 24\n\n\nO ile na jednym z opóźnień występuje istotna statystycznie autokorelacja, to rozkład reszt jest zdecydowanie bliższy rozkładowi normalnemu niż wcześniej.\n\nbox &lt;- Box.test(Model5_5$residuals, lag=24, fitdf=1, type=\"Lj\")\nbox \n\n\n    Box-Ljung test\n\ndata:  Model5_5$residuals\nX-squared = 20.226, df = 23, p-value = 0.6282\n\n\nI rzeczywiście, nie odrzucamy hipotezy zerowej, co świadczy o braku autokorelacji reszt modelu. Tak więc do dalszej prognozy użyję modelu ARMA(5,5).\nI to ten model wrzucam dalej do funkcji forecast.\n\nhorizon = 28 # to Jan 1 2027\nForecast = forecast(Model5_5, h = horizon, level = c(50,80,95))\nautoplot(Forecast)+theme_minimal()\n\n\n\n\n\n\n\n\nRezultat to przewidywane miesięczne zmiany procentowe dla przyszłych 28 obserwacji.\nTeraz przeprowadzam transformację z powrotem do wartości nominalnych.\n\n# Concatenating the historical data with the forecast\ntemp1 = ts_bind(Forecast$x, Forecast$mean)\n\n# I want to keep the original structire of the time series but remove the data\ntemp2=temp1\ntemp2[]=NA\n\n# Let the first value be the the first value from historical data\ntemp2[1] = as.numeric(M3seas[1])\n\n# Let every next value be defined as:\n# value for period t = value for period t-1 * (1 + percentage growth from t-1 to t)\nfor (observation in 2:length(temp1)){\n  temp2[observation] &lt;- temp2[observation-1] * (1+temp1[observation]/100)\n}\n\n# We have a plot for the month on month growth rate, but I would prefer to show the forecast in absolute values\nfcstStart = ts_summary(Forecast$mean)$start\nhistEnd   = ts_summary(Forecast$x)$end\nHistYoY   = ts_span(temp2, NULL, histEnd)\nFcstYoY   = ts_span(temp2, histEnd, NULL)\n\nTutaj wizualizuję swoją prognozę. Moim celem jest również zaznaczenie przedziałów ufności na wykresie.\n\n# User defined function that takes different vectors of predicted month-on-month growth, and converts them \n# to absolute values using the historical M3 data\n# In the code it's used for drawing the different confidence intervals\n\nts_forecast_plot &lt;- function(data){\n  # First value of the drawing is the last value from historical data, so wo dont have a gap with the drawiwing\n  templower = ts_span(temp1, histEnd, NULL)\n  templower[] = NA\n  #Using the formula from earlier\n  templower[1] = M3seas[length(M3seas)]\n  for (observation in 2:length(templower)){\n    templower[observation] &lt;- templower[observation-1] * (1+data[observation]/100)\n  }\n  templower # function returns times series of absolute values for the forecast\n}\n\nplot_index &lt;- index(FcstYoY)\n\n#Plotting the forecast\nplot(index(HistYoY), HistYoY, type = \"l\", xlim = c(2019, 2026), ylim = c(1000, 1400), \n     ylab = \"Billions of CHF\", xlab = \"Year\", \n     main = \"Swiss M3 money supply forecast\")\n\npolygon(c(plot_index[-29], rev(plot_index[-29])), c(ts_forecast_plot(Forecast$lower[,3])[-29], rev(ts_forecast_plot(Forecast$upper[,3])[-29])),\n        col = rgb(0,0,1,.1), lty = 0) # 95%\npolygon(c(plot_index[-29], rev(plot_index[-29])), c(ts_forecast_plot(Forecast$lower[,2])[-29], rev(ts_forecast_plot(Forecast$upper[,2])[-29])),\n        col = rgb(0,0,1,.4), lty = 0) # 80%\npolygon(c(plot_index[-29], rev(plot_index[-29])), c(ts_forecast_plot(Forecast$lower[,1])[-29], rev(ts_forecast_plot(Forecast$upper[,1])[-29])),\n        col = rgb(0,0,1,.7), lty = 0) # 50%\nlegend(2019, 1400, legend=c(\"95% confidence\", \"80% confidence\", \"50% confidence\", \"Forecast mean\"),\n       col=c(rgb(0,0,1,.1), rgb(0,0,1,.4), rgb(0,0,1,.7), \"black\"), lty = 1, lwd = c(12,12,12,2))\nlines(index(FcstYoY), FcstYoY, type = \"l\", col = \"black\", lwd = 2)"
  },
  {
    "objectID": "Projekty/R6Class/index.html",
    "href": "Projekty/R6Class/index.html",
    "title": "7. R6Class",
    "section": "",
    "text": "Projekt wykonany w ramach zajęć Zaawansowane programowanie w języku R.\n\nOpis projektu\nProjekt dotyczy rozszerzonej reprezentacji szeregu czasowego. W języku R jest wiele możliwości reprezentowania szeregów czasowych. Podstawowe klasy to ts i mts. Klasy, które rozszerzają te klasy to zoo i xts. Wszystkie te klasy reprezentują jedynie dane a więc dane dotyczące czasu i wartości. W tym projekcie chcemy do danych dołożyć operacje, które są wykonywane na szeregach czasowych oraz metody, które tworzą prognozy.\nTechnicznie, zadaniem w projekcie jest zdefiniowanie klasy timeSeries w modelu obiektowym R6, która na podstawie wektora określającego czas i wektora wartości, inicjalizuje instancję klasy. Metoda new powinna przyjmować dwa argumenty: times, który przyjmuje wektor czasów (i tutaj możemy wykorzystać dowolną klasę reprezentującą datę i czas, np. Date czy yearmon) oraz values, który przyjmuje wektor wartości.\nKlasa musi oferować następujące podstawowe metody.\n\nMetoda getTimes, która zwraca podany wektor czasów.\nMetoda getValues, która zwraca podany wektor wartości.\nMetoda getTimeSeries, która zwraca szereg czasowy. W rozwiązaniu proszę wykorzystać klasę xts.\n\nProjekt jest zatem rozszerzeniem klasy xts.\nPowyższe metody są typowymi fundamentalnymi metodami związanymi z szeregiem czasowym.\n\n\nMoja definicja funkcji\n\nlibrary(R6)\nlibrary(xts)\nlibrary(zoo)\nlibrary(tibble)\nlibrary(ggplot2)\n\ntimeSeries &lt;- R6Class(\n  classname = \"timeSeries\",\n  public = list(\n    times = NA,\n    values = NA,\n    table = NULL,\n    operations = list(),\n    models = list(),\n    paths = list(),\n    initialize = function(times, values) {\n      self$times &lt;- times\n      self$values &lt;- values\n      self$table &lt;- xts::xts(x = self$values, order.by = self$times)\n    },\n    \n    getTimes = function() {\n      self$times\n    },\n    \n    getValues = function() {\n      self$values\n    },\n    \n    getTimeSeries = function() {\n      self$table\n    },\n    \n    opsAppend = function(...) {\n      ops &lt;- list(...)\n      for (name in names(ops)) {\n        self$operations[[name]] &lt;- ops[[name]]\n      }\n    },\n    \n    opsRemove = function(...) {\n      keys &lt;- list(...)\n      for (key in keys) {\n        self$operations[[key]] &lt;- NULL\n      }\n    },\n    \n    opsList = function() {\n      data.frame(id = seq_along(self$operations), name = names(self$operations))\n    },\n    modelsAppend = function(...){\n      model &lt;- list(...)\n      for (name in names(model)) {\n        self$models[[name]] &lt;- model[[name]]\n      }\n    },\n    modelsRemove = function(...) {\n      keys &lt;- list(...)\n      for (key in keys) {\n        self$models[[key]] &lt;- NULL\n      }\n    },\n    modelsList = function() {\n      data.frame(id = seq_along(self$models), name = names(self$models))\n    },\n    pathsAppend = function(pathName, operations, model){\n      self$paths[[pathName]] &lt;- list(operations = operations, model = model)\n      },\n    pathsRemove = function(...) {\n      pathNames &lt;- list(...)\n      for (pathName in pathNames) {\n        self$paths[[pathName]] &lt;- NULL\n      }\n    },\n    pathsList = function() {\n      paths_df &lt;- do.call(rbind, lapply(names(self$paths), function(name) {\n        data.frame(\n          id = which(names(self$paths) == name),\n          name = name,\n          operations = paste(self$paths[[name]]$operations, collapse = \" → \"),\n          model = self$paths[[name]]$model,\n          stringsAsFactors = FALSE\n        )\n      }))\n      paths_df\n    },\n    pathsRun = function(pathName) {\n      if (!(pathName %in% names(self$paths))) {\n        stop(\"Path not found.\")\n      }\n      path &lt;- self$paths[[pathName]]\n      result &lt;- self$table\n      for (op in path$operations) {\n        result &lt;- self$operations[[op]](result)\n      }\n      prediction &lt;- self$models[[path$model]](result)\n      prediction\n    }\n    \n  )\n)\n\n\n\nPrzykłady\n\nPrzykład 1\nPoniższy przykład tworzy bardzo prosty szereg czasowy i pokazuje działanie opisanych powyżej metod.\nPrzykład pokazuje inicjalizację obiektu klasy timeSeries oraz wykorzytanie podstawowych metod. Na tej podstawie tworzony jest prosty wykres szeregu czasowego.\n\n### Tworzenie danych do szeregu czasowego: \nts &lt;- yearmon(2009) + (0:(5 * 12 - 1)) / 12\nvs &lt;- seq_along(ts) / 5 + cumsum(rnorm(5 * 12))\n\n### Inicjalizacja obiektu\ny &lt;- timeSeries$new(times = ts, values = vs)\n\n### Pobranie wartości\ny$getValues()\n\n [1]  1.739023  1.751959  1.536933  1.573317  1.435771  3.254487  4.173884\n [8]  5.465897  4.079754  4.812440  6.521490  6.052503  6.088417  4.785024\n[15]  4.597158  4.962038  5.160985  5.069666  4.700115  4.935296  5.526809\n[22]  7.771384  8.626130  8.800795  7.642527  8.989111  9.444234  7.297739\n[29]  7.816178  9.238599 11.235425 10.463964 10.922272  9.174508  8.571072\n[36]  8.709663  9.780848  9.709057  9.756521  8.367833  7.177976  8.012803\n[43]  8.026457  9.084549  9.477881  9.248018  9.076438  9.501167 10.854605\n[50] 10.602296  9.928934  9.981804 10.482215 11.020297 10.276780 10.035788\n[57] 11.010108  9.792936 11.449328 10.469109\n\n### Pobranie wektora czasów\ny$getTimes()\n\n [1] \"Jan 2009\" \"Feb 2009\" \"Mar 2009\" \"Apr 2009\" \"May 2009\" \"Jun 2009\"\n [7] \"Jul 2009\" \"Aug 2009\" \"Sep 2009\" \"Oct 2009\" \"Nov 2009\" \"Dec 2009\"\n[13] \"Jan 2010\" \"Feb 2010\" \"Mar 2010\" \"Apr 2010\" \"May 2010\" \"Jun 2010\"\n[19] \"Jul 2010\" \"Aug 2010\" \"Sep 2010\" \"Oct 2010\" \"Nov 2010\" \"Dec 2010\"\n[25] \"Jan 2011\" \"Feb 2011\" \"Mar 2011\" \"Apr 2011\" \"May 2011\" \"Jun 2011\"\n[31] \"Jul 2011\" \"Aug 2011\" \"Sep 2011\" \"Oct 2011\" \"Nov 2011\" \"Dec 2011\"\n[37] \"Jan 2012\" \"Feb 2012\" \"Mar 2012\" \"Apr 2012\" \"May 2012\" \"Jun 2012\"\n[43] \"Jul 2012\" \"Aug 2012\" \"Sep 2012\" \"Oct 2012\" \"Nov 2012\" \"Dec 2012\"\n[49] \"Jan 2013\" \"Feb 2013\" \"Mar 2013\" \"Apr 2013\" \"May 2013\" \"Jun 2013\"\n[55] \"Jul 2013\" \"Aug 2013\" \"Sep 2013\" \"Oct 2013\" \"Nov 2013\" \"Dec 2013\"\n\n### Pobranie szeregu czasowgo (klasa xts)\nhead(y$getTimeSeries(),10)\n\n             [,1]\nJan 2009 1.739023\nFeb 2009 1.751959\nMar 2009 1.536933\nApr 2009 1.573317\nMay 2009 1.435771\nJun 2009 3.254487\nJul 2009 4.173884\nAug 2009 5.465897\nSep 2009 4.079754\nOct 2009 4.812440\n\n### Stworzenie przykładowego wykresu\nggplot(\n  data = tibble(time = y$getTimes(), value = y$getValues()),\n  mapping = aes(x = time, y = value)\n) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Example of a time series\") +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\nPrzykład 2\nPodstawowe metody, opisane powyżej, nie wyczerpują operacji, które chcemy dodać do szeregu czasowego. Oczywiście katalog potencjalnych operacji nie jest skończony więc nie możemy dodać metod reprezentujących wszystkie potencjalne operacje. Z tego powodu chcemy mieć możliwość dodawania dowolnych operacji i następnie wiązania tych operacji. W pierwszej kolejności chcemy zbudować prosty system zarządzania operacjami. Na potrzeby tego projektu, operacja na szeregu czasowym, to dowolna funkcja, która jako argument przyjmuje szereg czasowy (klasa xts) i zwraca szereg czasowy (ponownie klasa xts). Tak więc musimy mieć następujące metody.\n\nMetoda opsAppend do dodawania operacji. Składania tej metody powinna być identyczna ze składnią funkcji list. Konieczne jest podanie kluczy jednoznacznie identyfikujących\nMetoda opsRemove do usuwania operacji. Metoda przyjmuje dowolną liczbę stringów, które są kluczami usuwanych operacji.\nMetoda opsList, która listuje operacje, które aktualnie są w liście dodanych operacji.\n\nPoniższy przykład pokazuje metody dodawania, listowania i usuwania operacji.\nW przykładzie tworzymy nowy obiekt, następnie dodajemy, listujemy i usuwamy operacje.\n\n### Tworzenie danych do szeregu czasowego: \nts &lt;- yearmon(2009) + (0:(5 * 12 - 1)) / 12\nvs &lt;- seq_along(ts) / 5 + cumsum(rnorm(5 * 12))\n\n### Inicjalizacja obiektu\ny &lt;- timeSeries$new(times = ts, values = vs)\n\n### Dodawanie operacji na szeregu czasowycvh\ny$opsAppend(\n  differencing = function(x) { diff(x = x, lag = 1, differences = 1) },\n  logs_abs = function(x) { log(abs(x)) },\n  na_omit = na.omit\n)\n\n### Listowanie operacji\ny$opsList()\n\n  id         name\n1  1 differencing\n2  2     logs_abs\n3  3      na_omit\n\n### Usuwanie operacji\ny$opsRemove(\"logs_abs\")\n\n### Listowanie operacji\ny$opsList()\n\n  id         name\n1  1 differencing\n2  2      na_omit\n\n\n\n\nPrzykład 3\nKolejnym elementem, które musi się znaleźć w klasie jest model predykcji. Na potrzeby tego projektu, przez model predkcji będziemy rozumieli dowolną funkcję, która jako argument przyjmuje obiekt klasy xts i zwraca obiekt tej klasy. Ponownie, katalog możliwych modeli predykcji nie jest zamknięty, więc również musimy mieć prosty system zarządzania. W szczególności klasa musi oferować następujące metody.\n\nMetoda modelsAppend, która pozwala na dodawanie modeli. Składnia tej metody powinna być taka jak funkcji list. Podobnie jak poporzednio, konieczne jest podanie unikalnych kluczy indetyfikujących modele.\nMetoda modelsRemove, która pozwana na usunięcie modeli. Metoda musi przyjmować stringi, które definiują dodane modele.\nMetoda modelsList, która listuje dodane modele.\n\nPoniższy przykład pokazuje zastosowanie opisanych metod.\nW przykładzie tworzymy nowy obiekt, następnie dodajemy, listujemy i usuwamy modele.\n\n### Tworzenie danych do szeregu czasowego: \nts &lt;- yearmon(2009) + (0:(5 * 12 - 1)) / 12\nvs &lt;- seq_along(ts) / 5 + cumsum(rnorm(5 * 12))\n\n### Inicjalizacja obiektu\ny &lt;- timeSeries$new(times = ts, values = vs)\n\n### Dodawanie prostego modelu liniowego\ny$modelsAppend(\n  linear_prediciton = function(x) {\n    dtemp &lt;- data.frame(\n      t = seq_along(coredata(x)),\n      z = coredata(x)\n    )\n    m &lt;- lm(formula = z ~ t, data = dtemp)\n    p &lt;- predict(\n      object = m,\n      newdata = data.frame(t = last(dtemp$t) + 1:6)\n    )\n    xts(\n      x = p,\n      order.by = index(last(x)) + (1:6) * deltat(x)\n    )\n  }\n)\n\n## Dodawanie modelu identyczności\ny$modelsAppend(\n  identity_prediction = function(x) {\n    x\n  }\n)\n\n### Listowanie modelu\ny$modelsList()\n\n  id                name\n1  1   linear_prediciton\n2  2 identity_prediction\n\n### Usuwanie modelu\ny$modelsRemove(\"identity_prediction\")\n\n### Listowanie modelu\ny$modelsList()\n\n  id              name\n1  1 linear_prediciton\n\n\n\n\nPrzykład 4\nSame operacje oraz modele nic nie robią. Kolejne zadanie to wiązanie operatorów i kończenie ich modelami predykcji. Powiązanie takie ma postać szereg czasowy → operator 1 → operator 2 → … → operator n → model. Każde takie powiązanie nazywamy dalej ścieżką obliczeniową (path). Klasa musi mieć narzędzia do tworzenia i zarządzania takimi ścieżkami obliczeniowymi. Klasa musi oferować następujące metody.\n\nMetoda pathsAppend musi pozwalać dodawać ścieżki obliczeniowe. Metoda ta powinna przyjmować trzy argumenty. Argument pathName, który jest stringiem i jest unikalny. Argument operations, który jest wektorem stringów definiujących dodane operacje. Argument model, który jest stringiem definiującym model predykcji. Razem metoda pozwala definiować ścieżkę obliczeniową.\nMetoda pathsRemove musi pozwalać na usuwanie poprzednio zdefiniowanych ścieżek obliczeniowych. Metoda przyjmuje dowolną liczbę stringów definiujących ścieżki obliczeniowe.\nMetoda pathsList, która listuje zdefiniowane ścieżki.\nMetoda pathsRun, która przyjmuje argument pathName, który jest stringiem definiującym ścieżkę.\n\nMetoda ta wykonuje obliczenia dla zdefiniowanej ścieżki a więc w kolejności zdefiniowanej w ścieżce stosuje funkcje definiujące operacje i na końcu model obliczeniowy. Wynikiem jest więc prognoza dla szeregu czasowego.\n\nlibrary(dplyr)\ndetach(\"package:dplyr\", unload = TRUE)\n\n### Tworzenie danych do szeregu czasowego:\nts &lt;- yearmon(2009) + (0:(2 * 12 - 1)) / 12\nvs &lt;- seq_along(ts) / 10 + cumsum(rnorm(2 * 12))\n\n### Inicjalizacja obiektu\ny &lt;- timeSeries$new(times = ts, values = vs)\n\n### Dodawanie operacji na szeregu czasowycvh\ny$opsAppend(\n  differencing = function(x) { diff(x = x, lag = 1, differences = 1) },\n  logs_abs = function(x) { log(abs(x)) },\n  na_omit = na.omit\n)\n\n### Dodawanie prostego modeli liniowego\ny$modelsAppend(\n  linear_prediciton = function(x) {\n    dtemp &lt;- data.frame(\n      t = seq_along(coredata(x)),\n      z = coredata(x)\n    )\n    m &lt;- lm(formula = z ~ t, data = dtemp)\n    p &lt;- predict(\n      object = m,\n      newdata = data.frame(t = last(dtemp$t) + 1:6)\n    )\n    xts(\n      x = p,\n      order.by = index(last(x)) + (1:6) * deltat(x)\n    )\n  }\n)\n\n## Dodawanie modelu identycznościowego\ny$modelsAppend(\n  identity_prediction = function(x) {\n    x\n  }\n)\n\n### Listing operacji i modeli\ny$opsList()\n\n  id         name\n1  1 differencing\n2  2     logs_abs\n3  3      na_omit\n\ny$modelsList()\n\n  id                name\n1  1   linear_prediciton\n2  2 identity_prediction\n\n### Dodawanie ścieżki z modelem liniowym\ny$pathsAppend(\n  pathName = \"linear with differencing\",\n  operations = c(\"differencing\", \"na_omit\"),\n  model = \"linear_prediciton\"\n)\n\n### Dodawanie ścieżki z modelem identycznościowym / pozwala na\n### zobaczenia co dokładnie wchodzi do modelu predykcji\ny$pathsAppend(\n  pathName = \"identity with differencing\",\n  operations = c(\"differencing\", \"na_omit\"),\n  model = \"identity_prediction\"\n)\n\n### Listowanie zdefiniowanych ścieżek\n\ny$pathsList()\n\n  id                       name             operations               model\n1  1   linear with differencing differencing → na_omit   linear_prediciton\n2  2 identity with differencing differencing → na_omit identity_prediction\n\n### Obliczanie zdefiniowanych ścieżek\nz &lt;- y$pathsRun(pathName = \"identity with differencing\")\nzF &lt;- y$pathsRun(pathName = \"linear with differencing\")\n\n### Tworzenie wykresu na podstawie wyników\nggplot(\n  data = tibble(time = index(z), value = coredata(z)),\n  mapping = aes(x = time, y = value)\n) +\n  geom_line() +\n  geom_point() +\n  geom_line(data = tibble(time = index(zF), value = coredata(zF)), color = \"red\") +\n  geom_point(data = tibble(time = index(zF), value = coredata(zF)), color = \"red\") +\n  coord_cartesian(ylim = c(-5, 5)) +\n  labs(title = \"Time series and forecast\") +\n  theme_light()"
  },
  {
    "objectID": "Projekty/MLR/index.html",
    "href": "Projekty/MLR/index.html",
    "title": "5. Function Factory",
    "section": "",
    "text": "Projekt wykonany w ramach zajęć Zaawansowane programowanie w języku R.\n\n\nOpis projektu\nZadanie polega na napisaniu funkcji createFitter(), która przyjmuje tylko jeden argument size. Zadaniem funkcji jest stworzenie nowej funkcji, tzw. fittera, która zawiera prostą sięć neuronową MLP o jednej warstwie ukrytej o wielkości size. Funkcja ta powinna przyjmować dwa argumenty: data, który jest ramką danych (alternatywnie obiektem dziedziczącym z data.frame, np. tbl_df) oraz formula, który jest formuła opisującą co w podanej ramce danych jest targetem a co features. Przykładowo, jeżeli w ramace danych mamy zmienne (kolumny) x i y to formuła y ~ x oznacza, że sieć na podstawie zmiennej x prognozuje zmienną y. Oczywiście powinny być wspierane skróty, np. y ~ . oznacza, że zmienna y jest prognozowana na podstawie wszystkich pozostałych w ramce danych zmiennych. Zadaniem fittera jest zdefiniowane nowej kolejnej funkcji, która jest predyktorem a więc funkcją, która dla podanych zmiennych zwraca predykcje. Tak więc fitter na podstawie podanej próby trenuje sieć neuronową i zwraca funkcję, predyktor, która zawiera wytrenowaną sieć neuronową i jej zadaniem jest tworzenie predykcji z wykorzystaniem wytrenowanej sieci neuronowej.\n\n\nMoje rozwiązanie\n\nlibrary(dplyr)\n\ncreateFitter &lt;- function(size) {\n  #createFitter upewnia się, że mamy właściwe biblioteki oraz tworzy kolejną funkcję\n  if(!require(nnet)){\n    install.packages(\"nnet\")\n    library(nnet)\n  } else {\n    library(nnet)\n  }\n  # Funkcja createFitter zwraca kolejną funckję \"fitter\"\n  return(function(data, formula){ \n    # Funkcja fitter tworzy sieć neuronową w ramach biblioteki nnet oraz tworzy definicję funkcji lines dla klasy data.frame. \n    # fitter\n    nn &lt;- nnet(formula, data, size = c(size), maxit=1000, rang = 0.1, decay = 5e-4, linout=T)\n    ## definicja f. lines dla klasy data.frame\n    e &lt;- parent.env(environment())\n    e$lines &lt;- function(x, ...) {\n      graphics::lines(x = x[,1], y = x[,2], ...)\n    }\n    \n    return(function(newData){\n      #Funkcja predyktor\n      #Zwraca dataframe ktory ma dwie kolumny, x ze zbioru wartości, których model wcześniej nie widział i y wyliczone na podstawie sieci neuronowej\n      out &lt;- data.frame(newData[,1], predict(nn, newData))\n      return(out)\n    })\n  })\n}\n\n\n\nPrzykłady\n\nPrzykład 1\n\n### Tworzenie przykładowych danych - zbiór treningowy\nd &lt;- tibble(\n  x = rnorm(10^3),\n  y = x^2 + 3 * cos(x) + rnorm(10^3, sd = 0.4)\n)\n\n### Tworzenie zbioru testowego\ndTest &lt;- tibble(\n  x = seq(\n    from = min(d$x),\n    to = max(d$x),\n    length.out = 100)) ## features\n\n\n### Tworzenie fittera. Poniżej wykorzystujemy jedynie 10 neuronów w\n### warstwie ukrytej.\nfitter &lt;- createFitter(size = 10)\n\n### Tworzenie predyktora. \npredictor &lt;- fitter(formula = y ~ x, data = d)\n\n\n### Wizualizacja przykładowych danych wyniku\nplot(d, pch = 20,\n     col = rgb(1, 0, .5, 0.2),\n     xlab = \"feature\", ylab = \"target\")\ngrid(lty = \"solid\", col = \"lightgray\")\n\nlines(x = predictor(newData = dTest),\n      col = rgb(.5, 0, 1, .9),\n      lwd = 2)\n\n\n\n\nPrzykład 1\n\n\n\n\n\n\nPrzykład 2\n\n### Tworzenie przykładowych danych - zbiór treningowy\nd &lt;- tibble(\n  x = rnorm(10^3),\n  y = x^2 + 3 * cos(x) + rnorm(10^3, sd = 0.4)\n)\n\n### Tworzenie zbioru testowego\ndTest &lt;- tibble(\n  x = seq(\n    from = min(d$x),\n    to = max(d$x),\n    length.out = 100)) ## features\n\n\n### Tworzesnie fittera. Poniżej wykorzystujemy jedynie 10 neuronów w\n### warstwie ukrytej.\nfitter &lt;- createFitter(size = 3)\n\n### Tworzenie predyktora. \npredictor &lt;- fitter(formula = y ~ x, data = d)\n\n\n### Wizualizacja przykładowych danych wyniku\n\nplot(d, pch = 20,\n     col = rgb(1, 0, .5, 0.2),\n     xlab = \"feature\", ylab = \"target\")\ngrid(lty = \"solid\", col = \"lightgray\")\n\nlines(x = predictor(newData = dTest),\n      col = rgb(.5, 0, 1, .9),\n      lwd = 2)\n\n\n\n\nPrzykład 2\n\n\n\n\n\n\nPrzyklad 3\n\n### Tworzenie przykładowych danych - zbiór treningowy\nd1 &lt;- tibble(\n  x = rnorm(10^3, mean = -5),\n  y = (x + 5)^2 + 3 * cos(x) + rnorm(10^3, sd = 0.4)\n)\nd2 &lt;- tibble(\n  x = rnorm(10^3, mean = 5),\n  y = (x - 5)^2 + 3 * cos(x) + rnorm(10^3, sd = 0.4)\n)\nd &lt;- rbind(d1, d2)\n\n### Tworzenie zbioru testowego\ndTest &lt;- tibble(\n  x = seq(\n    from = min(d$x),\n    to = max(d$x),\n    length.out = 100)) ## features\n\n\n### Tworzesnie fittera. Poniżej wykorzystujemy jedynie 10 neuronów w\n### warstwie ukrytej.\nfitter3 &lt;- createFitter(size = 3)\nfitter20 &lt;- createFitter(size = 20)\n\n### Tworzenie predyktora. \npredictor3 &lt;- fitter3(formula = y ~ x, data = d)\npredictor20 &lt;- fitter20(formula = y ~ x, data = d)\n\n\n### Wizualizacja przykładowych danych wyniku\n#| label: przyklad-3\n#| fig-cap: \"Przykład 3\"\n#| warning: false\nplot(d, pch = 20,\n     col = rgb(1, 0, .5, 0.2),\n     xlab = \"feature\", ylab = \"target\")\ngrid(lty = \"solid\", col = \"lightgray\")\nlines(x = predictor3(newData = dTest),\n      col = rgb(.5, 0, 1, .9),\n      lwd = 2)\nlines(x = predictor20(newData = dTest),\n      col = rgb(0, .5, 1, .9),\n      lwd = 2)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]